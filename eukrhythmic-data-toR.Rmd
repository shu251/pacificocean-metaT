---
title: "Compile eukrhythmic data in R"
author: "Sarah Hu"
date: "9/1/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Import data from eukrhythmic

Explanation of output data from eukrhythmic
-   00-nucleotide_assembly:
    -   MAD.filtered.nospace.fasta: Full length sequences of merged assembly groups (MAD) that have been de-duplicated
    
-   01-predicted_proteins:
    -   MAD.fasta.transdecoder.cds: Identified coding regions of transcripts from the Merged assembly groups (MAD)
    -   MAD.fasta.transdecoder.pep: Translated peptide sequences from the Merged assembly groups (MAD)
    
-   02-annotation_table:
    -   SeqID_Dict.csv: Original sequence names (MAD-based) that originate from rnaspades, megahit merged/deduplicates and the associated **ShortSeqID** that is found in the other annotation outputs.
    -   TaxonomicAndFunctionalAnnotations.csv: Taxonomic levels, GOs, PFAMs, and KEGG KOs - assigned by short seq ID and the full sequence ID.
    
-   03-abundance_tables:
    -   ReadTable_ByContig.csv: Matrix where row names indicate the ShortSeqID, and column headers are the sample IDs. Counts equal raw counts.
    -   SeqID_Dict.csv: same as above.
    -   TPMTable_ByContig.csv: Matrix where row names indicate ShortSeqID and column headers are sample IDs. Counts equate to TPM.

# Create SQL database with metatranscriptome data

```
module load GCCcore/12.2.0 
module load SQLite/3.39.4 
module load Python/3.10.8

module load GCC/11.2.0
module load OpenMPI/4.1.1
module load pandas/1.4.0-Python-3.9.6
```

In python (`python`):
```
# Import required libraries
import sqlite3
import pandas as pd

conn = sqlite3.connect('/scratch/user/skhu/SPOT-ALOHA/spot-aloha-metat.db')

tpm_data = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig.csv')

### Toy dataset
# conn = sqlite3.connect('/scratch/user/skhu/SPOT-ALOHA/toy-metat.db')

# tpm_data = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig_150k.csv')
####

## Set tpm_data object to SQL:
# tpm_data.to_sql, table name = "TPM", conn = sqlite db, if exists replace and do not index

tpm_data.to_sql('TPM',conn, if_exists='replace',index=False)


# Add metadata

metadata = pd.read_csv('/home/skhu/pacificocean-metaT/input-data/complete-sample-list.txt')
metadata.to_sql('metadata', conn, if_exists='replace', index=False)


# Add annotation data
taxfxn = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/02-annotation_table/TaxonomicAndFunctionalAnnotations.csv')
taxfxn.to_sql('annot', conn, if_exists='replace', index=False)

conn.close()

```
Resources:
* https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html
* https://www.geeksforgeeks.org/creating-a-sqlite-database-from-csv-with-python/
* https://mungingdata.com/sqlite/create-database-load-csv-python/


# Work with SQL database via tidyverse

```{r}
# install.packages("RSQLite")
# install.packages("dbplyr")
# install.packages("tidyverse")

## Issue with this install:
# install.packages("multidplyr", dependencies = TRUE)

# Tried individual
# install.packages("Rcpp")
# install.packages("RcppParallel", dependencies = TRUE)
# install.packages("qs")

# Tried from source
# install.packages("/scratch/user/skhu/R/library-4.0.3/RcppParallel_5.1.7.tar.gz", repos = NULL, type = "source")
# install.packages("/scratch/user/skhu/R/library-4.0.3/stringfish_0.15.7.tar.gz", repos = NULL, type = "source")
# install.packages("/scratch/user/skhu/R/library-4.0.3/qs_0.25.5.tar.gz", repos = NULL, type = "source")
# install.packages("/scratch/user/skhu/R/library-4.0.3/multidplyr_0.1.2.tar.gz", repos = NULL, type = "source")

# Tried from github
# devtools::install_github("tidyverse/multidplyr")

# Must install in this order
library(multidplyr)
library(tidyverse)
library(dbplyr)
library(RSQLite)
```

Import and query databases.
```{r}
metat <- DBI::dbConnect(RSQLite::SQLite(), "/scratch/user/skhu/SPOT-ALOHA/spot-aloha-metat.db")
# metat <- DBI::dbConnect(RSQLite::SQLite(), "input-data//toy-metat.db")
# metat <- DBI::dbConnect(RSQLite::SQLite(), "/scratch/user/skhu/SPOT-ALOHA/toy-metat.db")
```

```{r}
# tbls listed.
src_dbi(metat)

## Example output:
### tbls: TPM, metadata, annot
```


Interpret as R objects.
```{r}
metadata <- tbl(metat, "metadata")
tpm <- tbl(metat, "TPM")
annot <- tbl(metat, "annot")

# annot_df <- as.data.frame(annot) %>% partition(cluster = cluster)
# annot_df <- as.data.frame(annot)
# tmp_df <- as.data.frame(tpm)
# metadata_df <- as.data.frame(metadata)
# class(tpm_df)
```

Column "RUN" in metadata is associated with the column headers in TPM.

Set up run in parallel
```{r}
# install.packages("nycflights13")
library(nycflights13)
# tmp_csv <- read.csv("input-data/All_metadata.csv")
# head(tmp_csv)

parallel::detectCores() 

cluster <- new_cluster(16)
cluster

# Examples of how long it takes without running in parallel vs. running in parallel
system.time(flights %>% group_by(dest))

flights_party <- flights %>% group_by(dest) %>% partition(cluster)

system.time(re_group <- flights_party %>% collect())

system.time(flights %>% group_by(dest) %>% partition(cluster))

# tmp <- flights %>% partition(cluster)
# tmp
```

There are two ways to get data to the workers in cluster:
* partition() a data frame that already loaded in the interactive process.
* Load a different subset of the data in each worker.


> Does this partition(cluster) approach work with SQL collect step?

# Isolate taxonomy and functional keys

See Rscript `summary-sql.r`
```{r}
# tpm_party <- data.frame(tpm) %>% partition(cluster)
# annot_party <- data.frame(annot) %>% partition(cluster)
# class(annot_party)
# df <- party_df(cluster, "annot")

# Create unique taxa key, for downstream taxonomic plots
system.time(tax_key <- annot %>% 
  select(Domain:Species) %>%
    distinct() %>% collect())

# system.time(tax_key <- annot_df %>% 
#   select(Domain:Species) %>%
#   distinct() %>% partition(cluster))

fxn_key <- annot %>%
  select(PFAMs, KEGG_ko, GOs) %>% 
  distinct() %>% collect()
# class(fxn_key)
save(fxn_key, tax_key, file = "/scratch/user/skhu/SPOT-ALOHA/tax_annot_key_DFs.RData")
```


# Create matrix for estimating across replicates.

Start with all TPMs, pivot longer. Join with metadata, get mean TPM across replicates.
```{r}
tpm_annot <- tpm %>% 
  select(ShortSeqID, starts_with("SRR")) %>%
  pivot_longer(cols = starts_with("SRR"), names_to = "SRR_SAMPLEID", values_to = "TPM") %>% 
  filter(TPM > 0) %>% 
  left_join(metadata %>% select(SRR_SAMPLEID = RUN, DATE,SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH)) %>% 
  group_by(ShortSeqID, SAMPLENAME, SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(MEAN_TPM = mean(TPM)) %>% 
  left_join(annot)
# head(annot_df)
tpm_annot_df <- tpm_annot %>% collect()
# head(tpm_annot_df)
save(tpm_annot_df, file = "/scratch/user/skhu/SPOT-ALOHA/Avg_tpm_acrossreps_annot.RData")
```

# Stats on metatranscriptome run

## Annotated vs. unannotated

Average TPM, include annotations, and then subset to look at a high level.
```{r}
tpm_wfxnwtax <- tpm_df %>% 
  select(ShortSeqID, starts_with("SRR")) %>%
  pivot_longer(cols = starts_with("SRR"), names_to = "SRR_SAMPLEID", values_to = "TPM") %>% 
  filter(TPM > 0) %>% 
  left_join(metadata_df %>% select(SRR_SAMPLEID = RUN, DATE,SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH)) %>% 
  group_by(ShortSeqID, SAMPLENAME, SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(MEAN_TPM = mean(TPM)) %>% 
  left_join(annot_df)

tpm_annot_stats <- tpm_wfxnwtax %>% 
  group_by(SAMPLENAME, Domain, PFAMs, KEGG_ko) %>% 
    summarize(SUM_STATS = sum(MEAN_TPM),
              COUNT_STATS = n())

View(tpm_annot_stats)
# View(tpm_wfxnwtax)
# system.time(tpm_annot_stats_df <- tpm_annot_stats %>% collect())


save(tpm_annot_stats_df, file = "/scratch/user/skhu/SPOT-ALOHA/AnnotationStats.RData")
```


```{r}
# Get totals for annotated vs unannotated
data.frame(tpm_annot_stats_df) %>% 
  
# What is TPM total for Domain level? what is total number of annotated transcripts?
# What is TPM total for some kind of fxn annotation? How about only KEGGs?
# What is TPM total and counts for transcripts with both TAX and FXN annotation?
```

## Curate taxonomic information

```{r}
load("input-data/tax_annot_key_DFs.RData", verbose = TRUE)
```

In order to curate taxonomic output, use this approach:
```{r}
unique(tax_df$Domain)

# Keep only Eukaryota
t <- data.frame(tax_df) %>% 
  mutate(COUNT = 1) %>% 
  filter(Domain == "Eukaryota") %>% 
  group_by( Supergroup,  Phylum) %>% 
    summarise(SUM = sum(COUNT))
# View(t)
```


From SQL TPM matrix with annotations. Create several outputs for Supergroup, Phylum, and Class levels
```{r}
library(tidyverse);library(dbplyr);library(RSQLite)  
metat <- DBI::dbConnect(RSQLite::SQLite(), "/scratch/user/skhu/SPOT-ALOHA/spot-aloha-metat.db")
metadata <- tbl(metat, "metadata")
tpm <- tbl(metat, "TPM")
annot <- tbl(metat, "annot")

tpm_wfxnwtax <- tpm %>% 
  select(ShortSeqID, starts_with("SRR")) %>%
  pivot_longer(cols = starts_with("SRR"), names_to = "SRR_SAMPLEID", values_to = "TPM") %>% 
  filter(TPM > 0) %>% 
  left_join(metadata %>% select(SRR_SAMPLEID = RUN, DATE,SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH)) %>% 
  group_by(ShortSeqID, SAMPLENAME, SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(MEAN_TPM = mean(TPM)) %>% 
  left_join(annot)

# Supergroup
tax_sql_super <- data.frame(tpm_wfxnwtax) %>% 
filter(Domain == "Eukaryota") %>% 
  group_by( Supergroup,  SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(SUM_TPM = sum(MEAN_TPM))
cat("start collecting\n")
tax_super_df <- tax_sql_super %>% collect()
cat("finished\n\n")

# Phylum
tax_sql_phy <- data.frame(tpm_wfxnwtax) %>% 
filter(Domain == "Eukaryota") %>% 
  group_by( Supergroup,  Phylum, SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(SUM_TPM = sum(MEAN_TPM))
cat("start collecting\n")
tax_phy_df <- tax_sql_phy %>% collect()
cat("finished\n\n")

# Class
tax_sql_class <- data.frame(tpm_annot_df) %>% 
filter(Domain == "Eukaryota") %>% 
  group_by( Supergroup,  Phylum,  Class, SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(SUM_TPM = sum(MEAN_TPM))
cat("start collecting\n")
tax_class_df <- tax_sql_class %>% collect()
cat("finished\n\n")

save(tax_super_df, tax_phy_df, tax_class_df, file = "/scratch/user/skhu/SPOT-ALOHA/taxonomic-summaries.RData")
```



# Create toy dataset (of TPM) to ensure all code works

```
module load GCCcore/12.2.0 
module load SQLite/3.39.4 
module load Python/3.10.8

module load GCC/11.2.0
module load OpenMPI/4.1.1
module load pandas/1.4.0-Python-3.9.6
```

In python (`python`):
```
# Import required libraries
import sqlite3
import pandas as pd

conn = sqlite3.connect('/scratch/user/skhu/SPOT-ALOHA/toy-metat.db')

tpm_data = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig_150k.csv')

## Set tpm_data object to SQL:
# tpm_data.to_sql, table name = "TPM", conn = sqlite db, if exists replace and do not index

tpm_data.to_sql('TPM',conn, if_exists='replace',index=False)


# Add metadata

metadata = pd.read_csv('/home/skhu/pacificocean-metaT/input-data/complete-sample-list.txt')
metadata.to_sql('metadata', conn, if_exists='replace', index=False)


# Add annotation data
taxfxn = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/02-annotation_table/TaxonomicAndFunctionalAnnotations.csv')
taxfxn.to_sql('annot', conn, if_exists='replace', index=False)

conn.close()

```


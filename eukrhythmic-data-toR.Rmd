---
title: "Compile eukrhythmic data in R"
author: "Sarah Hu"
date: "9/1/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Import data from eukrhythmic

Explanation of output data from eukrhythmic
-   00-nucleotide_assembly:
    -   MAD.filtered.nospace.fasta: Full length sequences of merged assembly groups (MAD) that have been de-duplicated
    
-   01-predicted_proteins:
    -   MAD.fasta.transdecoder.cds: Identified coding regions of transcripts from the Merged assembly groups (MAD)
    -   MAD.fasta.transdecoder.pep: Translated peptide sequences from the Merged assembly groups (MAD)
    
-   02-annotation_table:
    -   SeqID_Dict.csv: Original sequence names (MAD-based) that originate from rnaspades, megahit merged/deduplicates and the associated **ShortSeqID** that is found in the other annotation outputs.
    -   TaxonomicAndFunctionalAnnotations.csv: Taxonomic levels, GOs, PFAMs, and KEGG KOs - assigned by short seq ID and the full sequence ID.
    
-   03-abundance_tables:
    -   ReadTable_ByContig.csv: Matrix where row names indicate the ShortSeqID, and column headers are the sample IDs. Counts equal raw counts.
    -   SeqID_Dict.csv: same as above.
    -   TPMTable_ByContig.csv: Matrix where row names indicate ShortSeqID and column headers are sample IDs. Counts equate to TPM.

# Create SQL database with metatranscriptome data

```
module load GCCcore/12.2.0 
module load SQLite/3.39.4 
module load Python/3.10.8

module load GCC/11.2.0
module load OpenMPI/4.1.1
module load pandas/1.4.0-Python-3.9.6
```

In python (`python`):
```
# Import required libraries
import sqlite3
import pandas as pd

conn = sqlite3.connect('/scratch/user/skhu/SPOT-ALOHA/spot-aloha-metat.db')

tpm_data = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig.csv')

### Toy dataset
# conn = sqlite3.connect('/scratch/user/skhu/SPOT-ALOHA/toy-metat.db')

# tpm_data = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig_150k.csv')
####

## Set tpm_data object to SQL:
# tpm_data.to_sql, table name = "TPM", conn = sqlite db, if exists replace and do not index

tpm_data.to_sql('TPM',conn, if_exists='replace',index=False)


# Add metadata

metadata = pd.read_csv('/home/skhu/pacificocean-metaT/input-data/complete-sample-list.txt')
metadata.to_sql('metadata', conn, if_exists='replace', index=False)


# Add annotation data
taxfxn = pd.read_csv('/scratch/user/skhu/SPOT-ALOHA/02-annotation_table/TaxonomicAndFunctionalAnnotations.csv')
taxfxn.to_sql('annot', conn, if_exists='replace', index=False)

conn.close()

```
Resources:
* https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html
* https://www.geeksforgeeks.org/creating-a-sqlite-database-from-csv-with-python/
* https://mungingdata.com/sqlite/create-database-load-csv-python/


# Work with SQL database via tidyverse

```{r}
# install.packages("RSQLite")
# install.packages("dbplyr")
# install.packages("tidyverse")

## Issue with this install:
# install.packages("multidplyr", dependencies = TRUE)

# Tried individual
# install.packages("Rcpp")
# install.packages("RcppParallel", dependencies = TRUE)
# install.packages("qs")

# Tried from source
# install.packages("/scratch/user/skhu/R/library-4.0.3/RcppParallel_5.1.7.tar.gz", repos = NULL, type = "source")
# install.packages("/scratch/user/skhu/R/library-4.0.3/stringfish_0.15.7.tar.gz", repos = NULL, type = "source")
# install.packages("/scratch/user/skhu/R/library-4.0.3/qs_0.25.5.tar.gz", repos = NULL, type = "source")
# install.packages("/scratch/user/skhu/R/library-4.0.3/multidplyr_0.1.2.tar.gz", repos = NULL, type = "source")

# Tried from github
# devtools::install_github("tidyverse/multidplyr")
```
```{r}
# Must install in this order
library(multidplyr)
library(tidyverse)
library(dbplyr)
library(RSQLite)
library(tictoc)
library(vroom)
```


Import and query databases.
```{r}
metat <- DBI::dbConnect(RSQLite::SQLite(), "/scratch/user/skhu/SPOT-ALOHA/spot-aloha-metat.db")
# metat <- DBI::dbConnect(RSQLite::SQLite(), "input-data/toy-metat.db")
# metat <- DBI::dbConnect(RSQLite::SQLite(), "/scratch/user/skhu/SPOT-ALOHA/toy-metat.db")
```

```{r}
# tbls listed.
src_dbi(metat)

## Example output:
### tbls: TPM, metadata, annot
```


Interpret as R objects.
```{r}
metadata <- tbl(metat, "metadata")
tpm <- tbl(metat, "TPM")
annot <- tbl(metat, "annot")

# Interpret as dataframes
metadata_df <- data.frame(metadata)
tic()
annot_df <- data.frame(annot) # large - 251.601 sec elapsed
toc()
# head(annot)
# ?group_walk()
```

Try VROOM

```{r}
# Regular
# tic();tpm <- vroom("../../../scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig_15k.csv");toc()

# tic();tpm <- vroom("../../../scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig.csv");toc()

# # Parallel?
# parallel::detectCores() 
# 
# cluster <- new_cluster(4)
# # cluster
# cluster_library(cluster, "dplyr")
# 
# # Use vroom to load
# cluster_send(cluster, tpm_para <- vroom::vroom("../../../scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig_15k.csv"))
# 
# # Party df, across workers
# tpm_para <- party_df(cluster, "tpm_para")
```

Generate a sampled 
```{r}
# tic()
# tpm_nonpara <- tpm %>% 
#   select(ShortSeqID, starts_with("SRR")) %>%
#   sample_frac(0.01) %>% 
#   pivot_longer(cols = starts_with("SRR"), names_to = "SRR_SAMPLEID", values_to = "TPM") %>% 
#   filter(TPM > 0)
# toc()
# dim(tpm_nonpara)
```


## Data table & reshape

```{r}
# install.packages("data.table")
# install.packages("reshape2")

library(data.table)
library(reshape2)
```
Got a separate table that is filtered and already in long format.
Import with data.table
```{r}
## Use this for all contigs
# tpm <- fread("../../../scratch/user/skhu/SPOT-ALOHA/03-abundance_tables/TPMTable_ByContig.csv")
# str(tpm)
# colnames(tpm)
# srrs <- as.character(colnames(tpm)[-1:-2])
# class(srrs)

## User this for smaller dataset
tpm_melt <- fread("../../../scratch/user/skhu/SPOT-ALOHA/filt_low_tpm_melt.csv")
colnames(tpm_melt)
tpm_melt$V1 <- NULL # remove excess column
tpm_melt <- select(tpm_melt, ShortSeqID, RUN = Sample, TPM)
```

```{r}
# tpm_melt <- melt(tpm, id.vars = "ShortSeqID")
# melt(setDT(m, keep.rownames = "Tickets"), id.vars = "Tickets")[, variable := NULL][value != "0"]
```

```{r}
# tic()
# tpm_wpara <- tpm %>% 
#   select(ShortSeqID, starts_with("SRR")) %>%
#   pivot_longer(cols = starts_with("SRR"), names_to = "SRR_SAMPLEID", values_to = "TPM") %>% 
#   filter(TPM > 0)
# toc()
```

Column "RUN" in metadata is associated with the column headers in TPM.

Set up run in parallel
```{r}
# install.packages("nycflights13")
# library(nycflights13)
# tmp_csv <- read.csv("input-data/All_metadata.csv")
# head(tmp_csv)

# parallel::detectCores() 

# cluster <- new_cluster(24)
# cluster
# cluster_library(cluster, "dplyr")
# 
# # Examples of how long it takes without running in parallel vs. running in parallel
# tic()
# flights %>% group_by(dest)
# toc()
# 
# tic()
# flights_party <- flights %>% group_by(dest) %>% partition(cluster)
# toc()
# 
# system.time(re_group <- flights_party %>% collect())
# 
# system.time(flights %>% group_by(dest) %>% partition(cluster))

# tmp <- flights %>% partition(cluster)
# tmp
```

There are two ways to get data to the workers in cluster:
* partition() a data frame that already loaded in the interactive process.
* Load a different subset of the data in each worker.


> Does this partition(cluster) approach work with SQL collect step?

# Isolate taxonomy and functional keys

See Rscript `summary-sql.r`
```{r}
# tpm_party <- data.frame(tpm) %>% partition(cluster)
# annot_party <- data.frame(annot) %>% partition(cluster)
# class(annot_party)
# df <- party_df(cluster, "annot")

# Create unique taxa key, for downstream taxonomic plots
system.time(tax_key <- annot %>% 
  select(Domain:Species) %>%
    distinct() %>% collect())

# system.time(tax_key <- annot_df %>% 
#   select(Domain:Species) %>%
#   distinct() %>% partition(cluster))

fxn_key <- annot %>%
  select(PFAMs, KEGG_ko, GOs) %>% 
  distinct() %>% collect()
# class(fxn_key)
save(fxn_key, tax_key, file = "/scratch/user/skhu/SPOT-ALOHA/tax_annot_key_DFs.RData")
```


# Create matrix for estimating across replicates.

Start with all TPMs, pivot longer. Join with metadata, get mean TPM across replicates.
```{r}
tpm_annot <- tpm %>% 
  select(ShortSeqID, starts_with("SRR")) %>%
  pivot_longer(cols = starts_with("SRR"), names_to = "SRR_SAMPLEID", values_to = "TPM") %>% 
  filter(TPM > 0) %>% 
  left_join(metadata %>% select(SRR_SAMPLEID = RUN, DATE,SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH)) %>% 
  group_by(ShortSeqID, SAMPLENAME, SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(MEAN_TPM = mean(TPM)) %>% 
  left_join(annot)
# head(annot_df)
tpm_annot_df <- tpm_annot %>% collect()
# head(tpm_annot_df)
# save(tpm_annot_df, file = "/scratch/user/skhu/SPOT-ALOHA/Avg_tpm_acrossreps_annot.RData")
```



Repeat with filtered dataset.

```{r}
head(tpm_melt)
```

```{r}
# class(metadata)
# metadata_df <- data.frame(metadata) %>% 
#   select(Sample = RUN, DATE,SAMPLENAME, SAMPLE_ID_PARSED,DEPTH_CATEGORY,REGION,PACIFIC_REGION,MONTH)
class(metadata_df)

tpm_mean_reps <- tpm_melt %>% 
  left_join(metadata_df) %>% 
  group_by(ShortSeqID, SAMPLENAME, SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION,PACIFIC_REGION,MONTH) %>% 
    summarise(MEAN_TPM = mean(TPM))

```

```{r}
tpm_mean_reps_annot <- tpm_mean_reps %>% 
  left_join(data.frame(annot))
# head(tpm_annot_df)

save(tpm_mean_reps, tpm_mean_reps_annot, file = "/scratch/user/skhu/SPOT-ALOHA/Avg_tpm_acrossreps_annot.RData")
```


### Repeat above, but in parallel
```{r}
# head(tpm_melt)
# head(metadata_df)
# head(annot_df)
```
Try group by and partition - via multidplyr
```{r}
cluster <- new_cluster(8)
```

```{r}
# Separate samples by partition
meta_cluster <- metadata_df %>% 
  group_by(SAMPLENAME, SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION, PACIFIC_REGION, MONTH) %>% 
  partition(cluster)

# Metatranscriptome samples have been partitioned to separate clusters == shards
# meta_cluster
```
Use the above so that meta_cluster == the metadata_df and groupby functions.

Add TPM with left_join, and average across replicates.
```{r}
# colnames(meta_cluster)
# tpm_mean_reps <- meta_cluster %>% 
  # left_join(data.frame(tpm_melt)) %>% # can't figure out how to use 'left_join' with data in shards?
  # summarise(MEAN_TPM = mean(TPM))
```


# Stats on metatranscriptome run

Import from Rdata saved file
```{r}
tic()
load("/scratch/user/skhu/SPOT-ALOHA/Avg_tpm_acrossreps_annot.RData", verbose = TRUE)
toc() #244.6 sec elapsed
# note: at this point, 12.75 GB is memory usage in R.
```
Try group by and partition to create shards - via multidplyr
```{r}
parallel::detectCores()

cluster <- new_cluster(12)
cluster
cluster_library(cluster, "dplyr")
# cluster <- new_cluster(8)

# Create a shard by sample
tic()
shard_sample <- tpm_mean_reps_annot %>%
  group_by(SAMPLENAME) %>%
  partition(cluster)
toc() #120.708 sec elapsed
```

```{r}
head(shard_sample)
class(shard_sample)
```


## Annotated vs. unannotated

Average TPM, include annotations, and then subset to look at a high level.

```{r}
tic()
tpm_sum_domain <- shard_sample %>% 
  group_by(SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION, PACIFIC_REGION, MONTH, Domain) %>% 
  summarise(SUM_TPM = sum(MEAN_TPM),
            COUNT_TRANSCRIPT = n()) %>% 
  collect()
toc() #6.697 sec elapsed

# head(tpm_sum_domain)
domain_stats <- tpm_sum_domain %>% 
  mutate(DOMAIN = str_squish(Domain)) %>%
  group_by(SAMPLE_ID_PARSED, DEPTH_CATEGORY, REGION, PACIFIC_REGION, MONTH, DOMAIN) %>% 
  summarise(SUM_TPM = sum(SUM_TPM),
            COUNT_TRANSCRIPT = sum(COUNT_TRANSCRIPT))
  
# unique(domain_stats$DOMAIN)
```

### by domain
```{r}
# head(domain_stats)
domain_stats %>%
  # group_by(SAMPLE_ID_PARSED, DOMAIN) %>% 
  # summarise(SUM_TPM_Domain = sum(SUM_TPM)) %>% 
  ggplot(aes(x = SAMPLE_ID_PARSED, y = SUM_TPM, fill = DOMAIN)) +
  geom_bar(stat = "identity", color = "black", position = "fill") +
  theme_linedraw() + theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)
  )

# COUNT_TRANSCRIPT
domain_stats %>%
  # group_by(SAMPLE_ID_PARSED, DOMAIN) %>% 
  # summarise(SUM_TPM_Domain = sum(SUM_TPM)) %>% 
  ggplot(aes(x = SAMPLE_ID_PARSED, y = COUNT_TRANSCRIPT, fill = DOMAIN)) +
  geom_bar(stat = "identity", color = "black", position = "stack") +
  theme_linedraw() + theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)
  )
```

Table reporting % of transcripts that were assigned various taxonomic levels. 
```{r}
# Total transcripts
total <- sum(domain_stats$COUNT_TRANSCRIPT)
# total
# Percent annotated domain and protein
domain_stats %>% 
  group_by(DOMAIN) %>% 
    summarise(TRANSCRIPT = sum(COUNT_TRANSCRIPT)) %>% 
  mutate(PERC = 100*(TRANSCRIPT/total))
```
> What is the difference between Unclassified and "NA"?

```{r}
head(shard_sample)
```


## by annotation
```{r}
tic()
tpm_sum_kegg <- shard_sample %>% 
  mutate(KEGG_pa = case_when(
    KEGG_ko == "-" ~ "Not annotated",
    TRUE ~ "Annotated"
  )) %>%
  group_by(SAMPLE_ID_PARSED, KEGG_pa) %>% 
  summarise(SUM_TPM = sum(MEAN_TPM),
            COUNT_TRANSCRIPT = n()) %>% 
  collect()
toc() # 7.065 sec elapsed

total <- sum(tpm_sum_kegg$COUNT_TRANSCRIPT)
total

# Percent annotated domain and protein
tpm_sum_kegg %>% 
  group_by(KEGG_pa) %>% 
    summarise(TRANSCRIPT = sum(COUNT_TRANSCRIPT)) %>% 
  mutate(PERC = 100*(TRANSCRIPT/total))
```

What percentage of the data am I using, when I isolate eukaryotic transcripts that also have an annotation?
```{r}
tic()
stats_all <- shard_sample %>% 
  mutate(KEGG_pa = case_when(
    KEGG_ko == "-" ~ "Not annotated",
    TRUE ~ "Annotated"
  )) %>%
  group_by(KEGG_pa, Domain, Supergroup) %>% 
  summarise(SUM_TPM = sum(MEAN_TPM),
            COUNT_TRANSCRIPT = n()) %>% 
  collect()
toc() # 3.692 sec elapsed

total_all <- sum(stats_all$COUNT_TRANSCRIPT)

# Report percentage domain and kegg annotated.
stats_all %>% 
  mutate(DOMAIN = str_squish(Domain)) %>% 
  group_by(KEGG_pa, DOMAIN) %>% 
  summarise(SUM_TPM = sum(SUM_TPM),
            COUNT_TRANSCRIPT = sum(COUNT_TRANSCRIPT),
            PERCENT = (100*(COUNT_TRANSCRIPT/total_all)))
```

> 18.1% of all transcripts were assigned eukaryote and had a kegg annotation.

Issue is with the NA Domain assignments, where 72% of the transcripts were assigned NA at the domain level and were annotated. What does this mean?

Save work here.
```{r}
save(shard_sample, file = "/scratch/user/skhu/SPOT-ALOHA/party_df_all.RData")
```


# Curate taxonomic information

```{r}
load("/scratch/user/skhu/SPOT-ALOHA/party_df_all.RData", verbose = TRUE)
```

```{r}
head(shard_sample)
```

```{r}
# Supergroup and phylum
tic()
euks_only_df <- shard_sample %>% 
  filter(Domain == "Eukaryota") %>% 
  group_by( Supergroup,  Phylum, SAMPLENAME, SAMPLE_ID_PARSED, 
            DEPTH_CATEGORY, REGION, PACIFIC_REGION, MONTH) %>% 
    summarise(SUM_TPM = sum(MEAN_TPM)) %>% 
  collect()
toc() #1.87 sec elapsed
# mutate(across(Domain:Species, str_squish(.))) %>% 
```

## Plot taxa at supergroup level

```{r}
unique(euks_only_df$Supergroup)
head(euks_only_df)
```

### by supergroup
```{r}
euks_only_df %>% 
  group_by(Supergroup, SAMPLE_ID_PARSED, PACIFIC_REGION, DEPTH_CATEGORY) %>% 
  summarise(SUM = sum(SUM_TPM)) %>% 
  ggplot(aes(x = SAMPLE_ID_PARSED, y = SUM, fill = Supergroup)) +
    geom_bar(stat = "identity", color = "black", position = "fill") +
    theme_linedraw() + theme(
      axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)
    )
```




# Session
```{r}
sessionInfo()
```



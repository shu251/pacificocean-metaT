---
title: "Compilation of eukrhythmic output"
execute:
  echo: true
  eval: false
format:
  html:
    code-overflow: wrap
editor: visual
---

# Working with eukrhythmic output files

**List of output directories**:

`final-files/`

-   `00-nucleotide_assembly/`
    -   `MAD.filtered.nospace.fasta`: Full length sequences of merged assembly groups (MAD) that have been de-duplicated
-   `01-predicted_proteins/`
    -   `MAD.fasta.transdecoder.cds`: Identified coding regions of transcripts from the Merged assembly groups (MAD)
    -   `MAD.fasta.transdecoder.pep`: Translated peptide sequences from the Merged assembly groups (MAD)
-   `02-annotation_table/`
    -   `TaxonomicAndFunctionalAnnotations.csv`: Taxonomic levels, GOs, PFAMs, and KEGG KOs - assigned by short seq ID and the full sequence ID.
-   `03-abundance_tables/`
    -   `SeqID_Dict_NoSpaceNames.csv`: key to link long sequence read IDs to ShortSeq IDs that will link to taxonomic and functional annotations

`intermediate-files/`

-   `04-compare`
    -   `14-MAD-mapping-filtered`: location of individual salmon outputs for all samples (quant.sf)


## Import library normalized count data

R script to run this: `scripts/run_tximport.R`.

Our goal is to take eukrhthymic estimated counts (from salmon) to get transcript-level abundance estimates that will account for gene length. The outcome from this is that we get average transcript length across samples. For this we want to import all data into DESeq using tximport as an interface.

-   tximport
    -   *Why tximport*? tximport allows us to correct for the changes in gene length across our samples. This way we can use transcript-level estimates for our metatranscriptomic analysis. Also, tximport knows the output from salmon, so we can easily put the salmon output into tximport. Then it can link directly to edgeR or DESeq2.
-   DESeq
    -   DESeq: Love, M.I., Huber, W., Anders, S. (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biology, 15:550. 10.1186/s13059-014-0550-8
    -   Explaination using DESeq: https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html
    -   https://bioconductor.org/packages/release/bioc/manuals/DESeq2/man/DESeq2.pdf

Script takes output from salmon counts and modifies for the gene length across all samples. The outcome will be the transcript-level estimates.

Output file is *tximport_metaT-ALOHA-CA.Rdata*

# Set up R environment

R libraries required to execute code in R. Load necessary libraries & get number of available threads for data.table.

```{r, message=FALSE, warning=FALSE}
# | message: false
# | warning: false
## Installations
# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("DESeq2")
# BiocManager::install("tximport")
library(data.table)
library(tidyr)
library(dplyr)
library(tximport)
library(readr)
num_threads <- getDTthreads()

# Conflicts between tidyverse and data.table can be ignored
library(DESeq2)
library(tidyverse)
```

Output files from`run_tximport.R` provides an RData file that can be used for the DESeq input file (`tximport_metaT-ALOHA-CA.Rdata`).

# Generate count tables using DESeq2

Import as DESeq object from tximport.

```{r}
# | message: false
# | warning: false
load("/scratch/group/hu-lab/pacocean-metaT/tximport_metaT-ALOHA-CA.Rdata", verbose = TRUE)
# colData : Rows of colData correspond to columns of countData
# design ~ x == serves the purpose of considering biological replicates
```

Working with R objects, `txi` (output from txi import script) and `sample_merged` (metadata table).

For below count tables, we can also add in annotation information.

```{r}
# taxfxn <- read.csv("/scratch/group/hu-lab/pacocean-metaT/TaxonomicAndFunctionalAnnotations.csv")

# Isolate what is needed from tax and fxn annotations for most analyses.
# taxfxn_mini <- taxfxn %>%
  # select(SequenceID, Domain:Species, PFAMs, KEGG_ko)
# save(taxfxn_mini, sample_merged, file = "input-data/annot_files.RData")

# Alternatively, load necessary files
load("input-data/annot_files.RData", verbose = TRUE)
```

## Import as DESeq object

See Rscript to run this `pacificocean-metaT/scripts/run_deseq_vst_rlog_transformed.R`.

See how to set up subsetting: https://github.com/WHOIGit/super-waffle/blob/main/01_seqpain_deseq.R

```{r}
ds_tpm_samplename <- DESeqDataSetFromTximport(txi,
                                    colData = sample_merged,
                                    design = ~0 + SAMPLENAME)

```

Subset data to keep only transcripts with \>10 tpm.

```{r}
keep <- rowSums(counts(ds_tpm_samplename)) >= 10
dds_subset <- ds_tpm_samplename[keep,]
```

`dds` includes \> 10. Now dim is 6972094, it was originally, 14737135. Keeping about 47% of data.

Run DESeq on all data to get dispersion information.

```{r}
dds_dis_all <- DESeq(ds_tpm_samplename)
# res_all <- results(dds_dis_all)

dds_dis_subset <- DESeq(dds_subset)
# res_subset <- results(dds_dis_subset)


# DESeq objects saved. Dispersions have been estimated for downstream stats.
# save(dds_dis_all, dds_dis_subset, file = "/scratch/group/hu-lab/pacocean-metaT/DESeq_Robjs_04142024.RData")
```

## Extract centered data

See "Count data transformations" in https://introtogenomics.readthedocs.io/en/latest/2021.11.11.DeseqTutorial.html

Use `vst` command to estimate dispersion. Variance stabilizing transformations (VST) (Tibshirani 1988; Huber et al. 2003; Anders and Huber 2010). Output should be transformed data on the log2 scale.

VST and rlog remove dependence of the variance on the mean. Both transformations consider the experiment specific trend of variance instead of the mean.

Above, the `DESeq()` was already run, so dispersions were estimated. Therefore use `blind = FALSE` below.


```{r}
# Estiamte scaled datasets by VST
vst_all <- vst(dds_dis_all, blind = FALSE) 
vst_subset <- vst(dds_dis_subset, blind = FALSE)

# Get data frames 
df_ctr_norm_vst <- as.data.frame(assay(vst_all))
df_ctr_norm_subset_vst <- as.data.frame(assay(vst_subset))
```

*rlog* is regularized log. It transforms the original count data into the log2 scale and fits a model with a term for each sample.

```{r}
rld_all <- rlog(dds_dis_all, blind = FALSE)
rld_subset <- rlog(dds_dis_subset, blind = FALSE)

df_ctr_norm_rld <- as.data.frame(assay(rld_all))
df_ctr_norm_subset_rld <- as.data.frame(assay(rld_subset))
```

Output from `pacificocean-metaT/scripts/run_deseq_vst_rlog_transformed.R`.

Save this centered data (2 ways) and reformat with annotations and more (see function below)
```{r}
# save(rld_all, rld_subset, df_ctr_norm_rld, df_ctr_norm_subset_rld, file = "/scratch/group/hu-lab/pacocean-metaT/normed_dfs_rld.RData")
# 
# save(vst_all, vst_subset, df_ctr_norm_vst, df_ctr_norm_subset_vst,
#      file = "/scratch/group/hu-lab/pacocean-metaT/normed_dfs_vst.RData")

# load("/scratch/group/hu-lab/pacocean-metaT/normed_dfs_vst.RData", verbose = TRUE)
# load("/scratch/group/hu-lab/pacocean-metaT/normed_dfs_rld.RData", verbose = TRUE)
```


TOY dataset to work with.
```{r}
# toy_df_ctr_norm_rld <- df_ctr_norm_rld %>% 
#   sample_n(600)
# 
# toy_df_ctr_norm_subset_rld <- df_ctr_norm_subset_rld %>% 
#   sample_n(600)
# 
# save(toy_df_ctr_norm_rld, toy_df_ctr_norm_subset_rld, file = "/scratch/group/hu-lab/pacocean-metaT/TOY_normed_dfs_rld.RData")
```


Function to combine replicates and include annotation information for normalized dataframes

Below is also a function in the scripts directory to assemble output dataframes with annotation information and average across replicates.

See script: `pacificocean-metaT/scripts/run_transformed_df_reformatting.R`.

```{r}
convert_format_scaled <- function(df){
  all_samples_col_header <- colnames(df)
  df %>% 
  # sample_n(1000) %>% #uncomment for testing
  rownames_to_column(var = "SequenceID") %>% 
  pivot_longer(cols = all_of(all_samples_col_header), names_to = "Sample_rep", values_to = "VALUE") %>% 
  left_join(sample_merged) %>% 
  unite(SAMPLE_NOREP, REGION, DEPTH_CATEGORY, sep = " ", remove = FALSE) %>% 
  group_by(SequenceID, SAMPLE_NOREP, REGION, DEPTH_CATEGORY, DEPTH, PACIFIC_REGION, LIGHT) %>% 
    summarize(MEAN_VALUE = mean(VALUE)) %>% 
  left_join(taxfxn_mini)
  }
```

```{r}
# rlog_format_subset <- convert_format_scaled(df_ctr_norm_subset_rld)
# rlog_format_all <- convert_format_scaled(df_ctr_norm_rld)
# 
# save(rlog_format_subset, rlog_format_all, file = "/scratch/group/hu-lab/pacocean-metaT/rlog_formatted_forlocaluse.RData")
# cat("\n\n Done with rlog \n\n")


# vst_format_subset <- convert_format_scaled(df_ctr_norm_subset_vst)
# vst_format_all <- convert_format_scaled(df_ctr_norm_vst)

# save(vst_format_subset, vst_format_all, file = "/scratch/group/hu-lab/pacocean-metaT/vst_formatted_forlocaluse.RData")
```


Generate a TOY dataset to work with locally.
```{r}
# TOY_vst_format_subset <- vst_format_subset %>% 
#   sample_n(600)
# 
# TOY_vst_format_all <- vst_format_all %>% 
#   sample_n(600)
# 
# save("/scratch/group/hu-lab/pacocean-metaT/TOY_vst_formatted_forlocaluse.RData")
load("/scratch/group/hu-lab/pacocean-metaT/TOY_vst_formatted_forlocaluse.RData")
```

> From here, move to **Ordination analysis** in the `metat-analysis.qmd` script.

## Extract count table

Start again with the `txi` object and get scaled TPM values.

```{r}
# load("/scratch/group/hu-lab/pacocean-metaT/tximport_metaT-ALOHA-CA.Rdata", verbose = TRUE)
library(tximport)

counts_scaled <- makeCountsFromAbundance(
  as.matrix(txi$counts),
  as.matrix(txi$abundance),
  as.matrix(txi$length),
  countsFromAbundance = "scaledTPM"
)

counts_df <- as.data.frame(counts_scaled)
counts_withreps <- counts_df
```

Rename so replicates have the same name for counts

```{r}
names_orig <- colnames(counts_df)
names_new <- sub("_[^_]+$", "", names_orig)
colnames(counts_df) <- names_new
```

Mean across columns that have the same name - which are replicates.

```{r}
mean_counts_df <- counts_df %>%
  cbind(as.list(.) %>%
    Filter(is.numeric, .) %>%
    split(names(.)) %>%
    lapply(as.data.frame) %>%
    lapply(rowMeans) %>%
    setNames(paste0("mean.", names(.)))) %>% 
  select(starts_with("mean"))
```

```{r}
# save(counts_withreps, mean_counts_df, sample_merged, file = "/scratch/group/hu-lab/pacocean-metaT/TPM-count-tables.RData")
```


### Set up toy dataset
```{r}
load("/scratch/group/hu-lab/pacocean-metaT/TPM-count-tables.RData", verbose = TRUE)
load("/scratch/group/hu-lab/pacocean-metaT/TOY_TPM-count-tables.RData", verbose = TRUE)
# TOY_mean_counts_df <- mean_counts_df %>% 
  sample_n(600)
# save(sample_merged, TOY_mean_counts_df, file = "/scratch/group/hu-lab/pacocean-metaT/TOY_TPM-count-tables.RData")
```


## Annotate count table

```{r}
# mean_counts_df <- TOY_mean_counts_df

mean_counts_annotated <- mean_counts_df %>% 
  rownames_to_column(var = "SequenceID") %>%
  left_join(taxfxn_mini) %>%
  pivot_longer(cols = starts_with("mean."), names_to = "sample_tmp", values_to = "TPM") %>% 
  filter(TPM > 0) %>% 
  mutate(Sample = str_remove(sample_tmp, "mean.")) %>% 
  left_join(sample_merged) %>% 
  select(-sample_tmp, -SAMPLENAME) %>% 
  unite(SAMPLENAME, PACIFIC_REGION, REGION, DEPTH_CATEGORY, sep = " ", remove = FALSE)

# save(mean_counts_annotated, file = "/scratch/group/hu-lab/pacocean-metaT/mean_counts_annotated.RData")
# save(mean_counts_annotated, file = "/scratch/group/hu-lab/pacocean-metaT/TOY_mean_counts_annotated.RData")
```


### Extract z-score table

Standardizing to z-scores will make it easier to compare across the large dataset. And we will be able to detect outliers and anomalies.

First to do some data quality control based on data table that includes all replicates.


```{r}
# load("/scratch/group/hu-lab/pacocean-metaT/mean_counts_annotated.RData", verbose = TRUE)
# glimpse(mean_counts_annotated)
```

#### Calculate Z-score over all transcripts.

```{r}
counts_zscore <- mean_counts_annotated %>% 
  group_by(SequenceID) %>% 
  mutate(sd_01 = sd(TPM), SD = case_when(sd_01 == 0 ~ 1,
                                         is.na(sd_01) ~ 1,
                                         TRUE ~ sd_01),
         z_score_transcript = (TPM - mean(TPM)) / SD)

cat("range:")
range(counts_zscore$z_score_transcript)
```


#### Calculate Z-score over transcripts by species
```{r}
# head(mean_counts_annotated)
```

```{r, fig.height=20, fig.width=10}
bytax_counts_zscore <-  mean_counts_annotated %>%
  mutate(across(c(Domain, Supergroup, Phylum, Class, Order, Family, Genus, Species), ~ as.character(str_squish(.)))) %>% 
  filter(Domain == "Eukaryota") %>% 
  # Taxonomic group curation
  mutate(SUPERGROUP = case_when(
    Supergroup == "Alveolata" ~ paste(Supergroup, Phylum, sep = "-"),
    (Class == "Bacillariophyta" & Supergroup == "Stramenopiles") ~ paste(Supergroup, "Diatom", sep = "-"),
    (Class != "Bacillariophyta" & Supergroup == "Stramenopiles") ~ paste(Supergroup, "Other", sep = "-"),
    Supergroup == "Archaeplastida" ~ "Chlorophyte",
    TRUE ~ Supergroup
  )) %>% 
  group_by(SequenceID, SUPERGROUP) %>% 
  mutate(sd_01 = sd(TPM), SD = case_when(sd_01 == 0 ~ 1,
                                         is.na(sd_01) ~ 1,
                                         TRUE ~ sd_01),
         z_score_transcript = (TPM - mean(TPM)) / SD)
# cat("range:")
# range(counts_zscore$z_score_transcript)
# svg("Rplot_metat_pca_wholecommunity.svg", width = 7, height = 7)
save(counts_zscore, bytax_counts_zscore, file = "zscore_whole_bytax.RData") 
```

> Take these and see if we can plot them directly. See section called, Whole community analysis z-score

### Extract only curated TPMs

```{r}
# load("/scratch/group/hu-lab/pacocean-metaT/mean_counts_annotated.RData", verbose = TRUE)
# glimpse(mean_counts_annotated)
```

#### Import KEGG IDs

```{r}
kegg <- read.csv("../KEGG_DB/combined_kegg.csv")
# head(kegg$KO_number)
curated_kegg <- read.csv("../KEGG_DB/reformat-kegg-pfam-skh.csv")

key_geneid <- curated_kegg %>% 
  select(-X) %>% 
  right_join(kegg %>% select(KEGG = KO_number, everything(), -X)) %>% 
  distinct() %>% 
  select(starts_with("KeggOrthology_"), Category01, Category02, FullName, GeneID, Gene_identification, KEGG, PFAM, Descriptions, REF = REFs)
```

Subset key_geneid dataframe to select what we want from it.

```{r}
kegg_ortho_based <- key_geneid %>% 
  select(KeggOrthology_B, KEGG, GeneID, Gene_identification) %>% 
  filter(!is.na(KeggOrthology_B)) %>% 
  distinct()
kegg_curated <- key_geneid %>% 
  select(Category01, Category02, KEGG, GeneID, Gene_identification) %>% 
  filter(!is.na(Category01)) %>% 
  distinct()
```


Isolate from `mean_counts_annotated`.
```{r}
mean_counts_curated_only <- curated_kegg %>% 
  left_join(mean_counts_annotated %>% 
              mutate(KEGG = str_remove(KEGG_ko, "ko:"))) %>%

save(mean_counts_curated_only, file = "/scratch/group/hu-lab/pacocean-metaT/mean_counts_curated_only.RData")
```

> Use above to address targeted questions 1 and 2.


# Metatranscriptome stats


```{r}
# load("/scratch/group/hu-lab/pacocean-metaT/mean_counts_annotated.RData", verbose = TRUE)
# load("input-data/annot_files.RData", verbose = TRUE)
# load("/scratch/group/hu-lab/pacocean-metaT/TPM-count-tables.RData", verbose = TRUE)

# TEST RUN:
load("/scratch/group/hu-lab/pacocean-metaT/TOY_TPM-count-tables.RData", verbose = TRUE)
mean_counts_df <- TOY_mean_counts_df
```


Report total number of transcripts after assembly and annotation.

```{r, echo=TRUE, eval=FALSE}
length(unique(taxfxn_mini$SequenceID))
# rows: 14,841,331

length(unique(rownames(mean_counts_df)))
# 14737135
```

The taxonomic and functional annotation output from Eukrhythmic has more than the total number of transcripts in the count table.

```{r, echo=TRUE, eval=FALSE}
in_counts <- as.character(unique(row.names(mean_counts_df)))

subset_taxfxn <- taxfxn_mini %>% 
  filter(SequenceID %in% in_counts)

table(subset_taxfxn$Domain)

subset_taxfxn %>% 
  filter(Domain == "Eukaryota") %>% 
  group_by(Supergroup) %>% 
    summarise(COUNT = n())

subset_01 <- subset_taxfxn %>% 
  filter(Domain == "Eukaryota") %>% 
  filter(Supergroup != "Unclassified")
dim(subset_01)
total <- dim(subset_01)[1]

# Number of unannotated
kegg <- length(unique((subset_01 %>% 
                         filter(KEGG_ko == "-"))$SequenceID))
go <- length(unique((subset_01 %>% 
                       filter(GOs == "-"))$SequenceID))
pfam <- length(unique((subset_01 %>% 
                         filter(PFAMs == "-"))$SequenceID))

# What transcripts have both taxonomic and functional annotation?
subset_02 <- subset_01 %>% 
  filter(Phylum != "Unclassified" & (KEGG_ko != "-" | GOs != "-" | PFAMs != "-"))

```



# Preprocess for taxonomic composition

Create dataframes to evaluate taxonomic diversity and composition across all sites.
```{r}
load("/scratch/group/hu-lab/pacocean-metaT/TPM-count-tables.RData", verbose = TRUE)
```

```{r}
annotated_mean <- dplyr::left_join(mean_counts_df %>%
                   mutate(SequenceID = rownames(mean_counts_df)),
                                 taxfxn_mini,
                                 by = "SequenceID")
```

Remove the duplicated annotations and make a base taxonomic dataframe for downstream work.

```{r, echo=TRUE, eval=FALSE}
# | echo: true
# | eval: false
tax_plot <- annotated_mean %>% 
  select(Domain:Species, starts_with("mean"), SequenceID) %>% 
  distinct()
# dim(tax_plot) #14737624\
```

```{r, echo=TRUE, eval=FALSE}
# | echo: true
# | eval: false
tax_only <- tax_plot %>% 
  select(-SequenceID) %>% 
  pivot_longer(cols = starts_with("mean"), names_to = "SAMPLE", values_to = "scaledTPM") %>% 
  group_by(SAMPLE, Domain, Supergroup, Phylum, Class, Order, Family, Genus, Species) %>% 
    summarise(SUM_scaledTPM = sum(scaledTPM)) 
# save(tax_only, file = "tax_only_08242023.RData")
```

# K-means clustering - pre-processing

* Unsupervised learning technique that we will use to group together observations.
* We provide a fixed number of clusters (centroid) that group togerher based on their signatures (similarities)


Use a series of Rscripts below. Start with `run-kmeans_01.R`

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
load("/scratch/group/hu-lab/pacocean-metaT/vst_formatted_forlocaluse.RData", verbose = TRUE)
```

> WHAT INPUT DO I USE HERE? is is the vst?


```{r}
# Modify input dataframe
kmeans_input_pac <- mean_ctr_df %>% 
  select(SequenceID, starts_with("mean.")) %>% 
  distinct() #%>%
  # sample_n(20000) # subsample for non-remote option

# colnames(kmeans_input_pac)
head(kmeans_input_pac)
```

We do not know the optimal number of clusters, so we have to look at the total within-cluster sum of squares versus the number of k. We want the total within cluster sum of squares `tot.withinss` to be smaller. So we want to pick the number of clusters that represents that, without getting too many clusters out.

Total within cluster sum of squares `tot.withinss`: the distance from all observations to the global centroid. Smaller values suggest that the observations within the cluster are closer together (or more similar).

```{r, fig.height=4, fig.width=6}
# | echo: true
# | eval: false

kclusts <-
  tibble(k = 5:35) %>%
  mutate(
    kclust = map(k, ~ kmeans(select(kmeans_input_pac, -SequenceID), .x)),
    glanced = map(kclust, glance)
  )

output_kclusts <- kclusts %>%
  unnest(cols = c(glanced))

write_delim(output_kclusts, file = "input-data/output_kclusts.txt")
```

Run the below code when you can use a visualizer.

```{r}
output_kclusts <- read_delim("input-data/output_kclusts.txt")

output_kclusts %>% 
  ggplot(aes(x = k, y = tot.withinss)) +
    geom_line(alpha = 0.5, size = 1.2, color = "darkgreen") +
    geom_point(size = 2, color = "darkgreen") +
  theme_linedraw() +
  geom_vline(xintercept = 25, color = "orange")
```

Based on the output above, clusters between 20-25 should be okay. I plan to use 25, where the orange line is showing the main "elbow" of the figure.

Run k-means clustering with our chosen number of clusters, See script `run-kmeans_02.R`

```{r}
# | echo: true
# | eval: false
pac25_clust <- kmeans(select(kmeans_input_pac, -SequenceID), centers = 25)

summary(pac25_clust)


broom::tidy(pac25_clust)
# ?augment()

augment_pacocean <- augment(pac25_clust, kmeans_input_pac)
df_kmeans_pacoce <- (data.frame(augment_pacocean))

save(df_kmeans_pacoce, file = "kmeansoutput-pacificocean-metaT.RData")
```

# BREAK

# DEseq2 reanalysis for DE genes

Repeat DESeq2 design to extracted differentially expressed genes for specific patterns below. Subset is required ahead of time - we can do this with txi directly.

There are a few different ways we want to perform the untargeted analysis. First we will do a 'whole community' series of analyses to look at overall amount of differentially expressed genes. Below we will set up parameters associated with the queries we've planned.

See script `scripts/run_get_params.R` This is stored on GRACE.

## Create subset parameters

### Subset samples as parameters

Use the metadata data frame to create sample lists for the comparisons we want to do.

```{r}
metadata <- read.csv("input-data/sample-list-revised.txt")
```

For the whole community work, we want to compare CA vs NPSG and euphotic vs. subeuphotic.

```{r}
all_samples <- metadata %>% 
  select(sample = SAMPLE)

npsg_only <- metadata %>% 
  filter(PACIFIC_REGION == "NPSG") %>% 
  select(sample = SAMPLE)
# Compare euphotic and subeuphotic
# Use this to compare across months too

ca_only <- metadata %>% 
  filter(PACIFIC_REGION != "NPSG") %>% 
  select(sample = SAMPLE)
# Compare euphotic and subeuphotic

euphotic <- metadata %>% 
  filter(LIGHT == "Euphotic")%>% 
  select(sample = SAMPLE)
# Compare NPSG to CA euphotic zone

subeuphotic <- metadata %>% 
  filter(LIGHT != "Euphotic")%>% 
  select(sample = SAMPLE)
# Compare NPSG to CA subeuphotic zone
```

### Subset genes & taxa as parameters

Need to make a list of the `SequenceID` from the taxonomy and functional annotations.

```{r}
taxfxn <- read.csv("TaxonomicAndFunctionalAnnotations.csv")
```

#### Genes

Determine character lists from gene list as subsets for our later queries.

```{r}
# Get list of annotations where a GO, PFAM, and KEGG ID were assigned.
genes_fxn_all <- as.character(
  filter(taxfxn, GOs != "-" & PFAMs != "-" & KEGG_ko != "-") %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]]) #this line outputs the selected vector from the pipe

# Removing unclassified and unannotated sequences
genes_tax_fxn_all <- as.character(
  filter(taxfxn, GOs != "-" & PFAMs != "-" & KEGG_ko != "-"
         & Domain == "Eukaryota" & Supergroup != "Unclassified") %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])
```

From KEGG database reformatting make `key_geneid`. Isolate genes that are curated.

```{r}
kegg <- read.csv("../KEGG_DB/combined_kegg.csv")
head(kegg$KO_number)
curated_kegg <- read.csv("../KEGG_DB/reformat-kegg-pfam-skh.csv")

key_geneid <- curated_kegg %>%
  select(-X) %>%
  right_join(kegg %>% select(KEGG = KO_number, everything(), -X)) %>%
  distinct() %>%
  select(starts_with("KeggOrthology_"), Category01, Category02, FullName, GeneID, Gene_identification, KEGG, PFAM, Descriptions, REF = REFs)

# write.csv(key_geneid, file = "keygene_id.csv")
```

```{r}
kegg_keep <- as.character(key_geneid %>% 
  filter(Category01 != "" & !(is.na(Category01))) %>% 
  select(KEGG) %>% 
  .[["KEGG"]])
# length(kegg_keep)

genes_kegg_curated <- as.character(taxfxn %>%
    mutate(KEGG_mod = str_remove_all(KEGG_ko, "ko:")) %>% 
    filter(KEGG_mod %in% kegg_keep) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])
```

#### Taxa

Isolate transcript IDs (*SequenceID*) of individual taxa. For each taxa subset, we are also only selecting transcript IDs with PFAM or KEGG IDs.

For queries, we want to isolate:

```{r}
euks_only <- as.character(
  filter(taxfxn, Domain == "Eukaryota" & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])

diatom <- as.character(
  filter(taxfxn, Class == "Bacillariophyta" & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]]) 

#Dinoflagellata pPhylum
dinos <- as.character(
  filter(taxfxn, Phylum == "Dinoflagellata" & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]]) 

#Haptophyta in phylum
hapto <- as.character(
  filter(taxfxn, Phylum == "Haptophyta" & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])

# Chlorophyta
chloro <- as.character(
  filter(taxfxn, Phylum == "Chlorophyta" & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])

#Ciliophora
ciliate <- as.character(
  filter(taxfxn, Phylum == "Ciliophora" & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])

# Rhizaria at supergroup
rhizaria <- as.character(
  filter(taxfxn, Supergroup == "Rhizaria" & (PFAMs != "-" | KEGG_ko != "-")) %>% 
    select(SequenceID) %>% 
    .[["SequenceID"]])
```

Save objects for subseting.

```{r}

save(
  # These are data frames
  all_samples, npsg_only, ca_only, euphotic, subeuphotic,
  # these are lists (character lists)
     genes_fxn_all, genes_tax_fxn_all, key_geneid, genes_kegg_curated, 
     euks_only, diatom, dinos, hapto, chloro, ciliate, rhizaria,
     file = "sample-gene-lists-forTXI.RData")
```

### Txi function

Code for this function is from: https://rdrr.io/github/hcnh174/hlsgr/man/subsetTxi.html Code: https://rdrr.io/github/hcnh174/hlsgr/src/R/rnaseq.R

```{r}
# Subset txi directly
subsetTxi <- function(txi, samples, include_genes=rownames(txi$counts))
  {
  genes <- rownames(txi$counts)[rownames(txi$counts) %in% include_genes]
  txi$abundance <- txi$abundance[genes, samples$sample]
  txi$counts <- txi$counts[genes, samples$sample]
  txi$length <- txi$length[genes, samples$sample]
  return(txi)
  }

# Example usage 
# tmp <- sample(taxfxn$SequenceID,10,replace = FALSE)
# pola <- data.frame(sample = c("PortofLA_1", "PortofLA_2"))
# txi_pola <- subsetTxi(txi, pola, tmp)
```

# Whole community DESeq script

Compare across light and pacific region, first isolate only eukaryotes and annotated transcripts.

## All samples

See script `scripts/run_txi_wholecomm.R`.

```{r}
# Subset eukaryotes only, and keep all samples.
txi_euk_annot <- subsetTxi(txi, all_samples, euks_only)

ds_tpm_light <- DESeqDataSetFromTximport(txi_euk_annot,
                                              colData = sample_merged,
                                              design = ~0 + LIGHT)

ds_tpm_pac <- DESeqDataSetFromTximport(txi_euk_annot,
                                              colData = sample_merged,
                                              design = ~0 + PACIFIC_REGION)

ds_tpm_lightpac <- DESeqDataSetFromTximport(txi_euk_annot,
                                              colData = sample_merged,
                                              design = ~0 + PACIFIC_REGION + LIGHT)

save(ds_tpm_light, ds_tpm_pac, ds_tpm_lightpac, file = "light-pacregion-deseq.RData")
```

## By region

See script `scripts/run_txi_region.r`.

```{r}
# Subset txi
txi_npsg <- subsetTxi(txi, npsg_only, euks_only)

# Reset sample_merged
## Subset
tmp_sample_merged <- sample_merged %>% 
  filter(Sample_rep %in% as.character(npsg_only$sample))
## Set names
rownames(tmp_sample_merged) <- tmp_sample_merged$Sample_rep
rownames(tmp_sample_merged) <- colnames(txi_npsg$counts)

# Compare Euphotic vs. sub-euphotic samples in the NPSG
ds_tpm_npsg_light <- DESeqDataSetFromTximport(txi_npsg,
                                              colData = tmp_sample_merged,
                                              design = ~0 + LIGHT)

# Compare July vs. March in the NPSG
ds_tpm_npsg_month <- DESeqDataSetFromTximport(txi_npsg,
                                              colData = tmp_sample_merged,
                                              design = ~0 + MONTH)

save(ds_tpm_npsg_light, ds_tpm_npsg_month, file = "/vortexfs1/scratch/sarahhu/txi-objs-metaT/npsg-deseq.RData")
```

```{r}
txi_ca <- subsetTxi(txi, ca_only, euks_only)

tmp_sample_merged <- sample_merged %>% 
  filter(Sample_rep %in% as.character(ca_only$sample))
rownames(tmp_sample_merged) <- tmp_sample_merged$Sample_rep
rownames(tmp_sample_merged) <- colnames(txi_ca$counts)

# Compare euphotic vs. subeuphotic in coastal California
## Includes Port of LA and Catalina
ds_tpm_ca_light <- DESeqDataSetFromTximport(txi_ca,
                                              colData = tmp_sample_merged,
                                              design = ~0 + LIGHT)

save(ds_tpm_ca_light, file = "/vortexfs1/scratch/sarahhu/txi-objs-metaT/ca-deseq.RData")

##
rm(txi_npsg);rm(txi_ca) #Save room
```

## By light availability

See script `scripts/run_txi_light.r`.

```{r}
# Subset txi
txi_euph <- subsetTxi(txi, euphotic, euks_only)

tmp_sample_merged <- sample_merged %>% 
  filter(Sample_rep %in% as.character(euphotic$sample))
rownames(tmp_sample_merged) <- tmp_sample_merged$Sample_rep
rownames(tmp_sample_merged) <- colnames(txi_euph$counts)

# Compare CA versus NPSG within euphotic samples
ds_tpm_euphotic <- DESeqDataSetFromTximport(txi_euph,
                                              colData = tmp_sample_merged,
                                              design = ~0 + PACIFIC_REGION)



txi_subeuph <- subsetTxi(txi, subeuphotic, euks_only)

tmp_sample_merged <- sample_merged %>% 
  filter(Sample_rep %in% as.character(subeuphotic$sample))
rownames(tmp_sample_merged) <- tmp_sample_merged$Sample_rep
rownames(tmp_sample_merged) <- colnames(txi_subeuph$counts)

# Compare CA versus NPSG at subeuphotic depths
ds_tpm_subeuphotic <- DESeqDataSetFromTximport(txi_subeuph,
                                              colData = tmp_sample_merged,
                                              design = ~0 + PACIFIC_REGION)

save(ds_tpm_subeuphotic, ds_tpm_euphotic, file = "/vortexfs1/scratch/sarahhu/txi-objs-metaT/euphotic-subeuphotic-deseq.RData")

# save(txi_euph, txi_subeuph, file = "/vortexfs1/scratch/sarahhu/txi-objs-metaT/light_txi.RData")
```


## Question 1

For the first of our two core questions, we want to know what genes are significantly differentially expressed among the euphotic zone samples for the dominant protistan phytoplankton. We are specifically focusing on diatoms, chlorophytes, archaeplastidia (chlorophya), dinoflagellates, and haptophytes for this.

> How does nutrient utilization among euphotic zone phytoplankton vary between coastal California and the NPSG?

`/scripts/run_euphotic_deseq_taxa.R`

```{r}
# Function to subset txi by individual taxa and perform DESeq

deseq_region_bytax <- function(sample_set, gene_set){
  # First incorporate the txi subset fxn
  subsetTxi <- function(txi, samples, include_genes=rownames(txi$counts))
  {
    genes <- rownames(txi$counts)[rownames(txi$counts) %in% include_genes]
    txi$abundance <- txi$abundance[genes, samples$sample]
    txi$counts <- txi$counts[genes, samples$sample]
    txi$length <- txi$length[genes, samples$sample]
    return(txi)
  }
  # Run subset and sample merge re-set
  txi_output <- subsetTxi(txi, sample_set, gene_set)
  # This script will keep replacing tmp_sample_merged
  tmp_sample_merged <- sample_merged %>% 
    filter(Sample_rep %in% as.character(sample_set$sample))
  rownames(tmp_sample_merged) <- tmp_sample_merged$Sample_rep
  rownames(tmp_sample_merged) <- colnames(txi_output$counts)
  #
  # Import as DESeq object - use PACIFIC_REGION in the design
  # DESeq
  ds_tpm_output <- DESeqDataSetFromTximport(txi_output,
                                            colData = tmp_sample_merged,
                                            design = ~0 + PACIFIC_REGION)
  # return(ds_tpm_output)
  # Further process DESeq
  groupsize <- 2 # Transcript to consider, must be in at least 3 samples
  keep <- rowSums(counts(ds_tpm_output) >= 10) >= groupsize # And have >= to 10 counts
  ds_tpm_output_filtered <- ds_tpm_output[keep,]
  ###
  # Filtering stats:
  cat("\nStarted with ", dim(ds_tpm_output)[1], "observations. Filtering by 2 samples and 10 counts resulted in,", dim(ds_tpm_output_filtered)[1], ", which is", (100*(dim(ds_tpm_output_filtered)[1]/dim(ds_tpm_output)[1])), "% of the data.\n\n")
  ###
  #
  ## Positive log fold change == up regulared in CA, compared to NPSG
  ds_tpm_output_filtered$PACIFIC_REGION <- factor(ds_tpm_output_filtered$PACIFIC_REGION, levels = c("NPSG", "CA"))
  de_tax_output <- DESeq2::DESeq(ds_tpm_output_filtered)
  resultsNames(de_tax_output)
  summary(de_tax_output)
  return(de_tax_output)
  cat("\n\nCompleted.\n\n")
}
```

```{r}
## Apply to each taxa

# From the euphotic samples, what are DE genes among haptophytes between CA and NPSG?
cat("\n\nDiatoms start.\n\n")
de_diatom <- deseq_region_bytax(euphotic, diatom)

cat("\n\Haptophytes start.\n\n")
# From the euphotic samples, what are DE genes among haptophytes between CA and NPSG?
de_hapto <- deseq_region_bytax(euphotic, hapto)


cat("\n\Dinoflagellates start.\n\n")
# From the euphotic samples, what are DE genes among Dinoflagellates between CA and NPSG?
de_dinos <- deseq_region_bytax(euphotic, dinos)

cat("\n\Chlorophytes start.\n\n")
# From the euphotic samples, what are DE genes among chlorophytes between CA and NPSG?
de_chloro <- deseq_region_bytax(euphotic, chloro)

save(de_diatom, de_hapto, de_dinos, de_chloro, file = "/scratch/group/hu-lab/pacocean-metaT/Robjs/euphotic_by_taxa.RData")
```

## Question 2

We can repeat the above approach, but select different taxa.

> Do we see a similar euphotic vs. sub-euphotic shift in the metabolic potential of taxa observed at coastal California and the NPSG?

Use `scripts/run_bydepth_deseq_taxa.R`.

# July versus March for NPSG

```{r}
library(tidyverse)
library(DESeq2)
load("/scratch/group/hu-lab/pacocean-metaT/Robjs/npsg-deseq.RData", verbose = TRUE)
# Compare July vs. March in the NPSG
# ds_tpm_npsg_month <- DESeqDataSetFromTximport(txi_npsg,
#                                               colData = tmp_sample_merged,
#                                               design = ~0 + MONTH)
```

How many genes are differentially expressed between July and March?

```{r}
## Positive log fold change == up regulated in July, compared to March
ds_tpm_npsg_month$MONTH <- factor(ds_tpm_npsg_month$MONTH, levels = c("March", "July"))

de_month <- DESeq(ds_tpm_npsg_month)

results_month <- results(de_month, alpha=0.05)
# plotMA(results_month)
out <- summary(results_month)
write.csv(out, file = "summary-months.csv")

# Plot log fold change
svg("rplot-month.svg", width = 9, height = 8)
data.frame(results_month) %>% 
  mutate(REGULATION = case_when(
    log2FoldChange > 0 ~ "upregulated in July",
    log2FoldChange < 0 ~ "upregulated in March"
  ),
  SIGNIFICANT = case_when(
    pvalue <= 0.05 ~ "Significantly",
    TRUE ~ "Not significantly"
  )) %>% 
  ggplot(aes(x = baseMean, y = log2FoldChange, color = SIGNIFICANT)) +
    geom_point(stat = "identity") +
    scale_x_log10() +
    theme_classic() +
    scale_color_manual(values = c("#878787", "#d73027")) +
    labs(title = mcols(results_month)$description[2])
dev.off()

# Get table
month_transcripts <- data.frame(results_month) %>% 
  mutate(REGULATION = case_when(
    log2FoldChange > 0 ~ "upregulated in July",
    log2FoldChange < 0 ~ "upregulated in March"
  ),
  SIGNIFICANT = case_when(
    pvalue <= 0.05 ~ "Significantly",
    TRUE ~ "Not significantly"
  )) %>% 
  filter(SIGNIFICANT == "Significantly") %>% 
  rownames_to_column(var = "SequenceID")

write.csv(month_transcripts, file = "/scratch/group/hu-lab/pacocean-metaT/month-transcripts.csv")
```



## RM BELOW?
# Curated genes only

Here, we isolated annotated transcripts that we curated ourselves.

```{r}
library(tximport)
library(tidyverse)


all_samples <- metadata %>% 
  select(sample = SAMPLE)

txi_curated <- subsetTxi(txi, all_samples, genes_kegg_curated)


counts_scaled_curated <- makeCountsFromAbundance(
  as.matrix(txi_curated$counts),
  as.matrix(txi_curated$abundance),
  as.matrix(txi_curated$length),
  countsFromAbundance = "scaledTPM"
)

counts_df_curated <- as.data.frame(counts_scaled_curated)

names_orig <- colnames(counts_df_curated)
names_new <- sub("_[^_]+$", "", names_orig)
colnames(counts_df_curated) <- names_new

mean_counts_df_curated <- counts_df_curated %>%
  cbind(as.list(.) %>%
    Filter(is.numeric, .) %>%
    split(names(.)) %>%
    lapply(as.data.frame) %>%
    lapply(rowMeans) %>%
    setNames(paste0("mean.", names(.)))) %>% 
  select(starts_with("mean"))


counts_curated <- mean_counts_df_curated %>% 
  rownames_to_column(var = "SequenceID") %>% 
  left_join(taxfxn)

save(counts_curated, sample_merged, file = "Avg_scaled_tpm_curated_08252023.RData")
```

```{r}
tmp_sample_merged <- sample_merged %>% 
  filter(Sample_rep %in% as.character(all_samples$sample))

rownames(tmp_sample_merged) <- tmp_sample_merged$Sample_rep
rownames(tmp_sample_merged) <- colnames(txi_curated$counts)

ds_tpm_curated <- DESeqDataSetFromTximport(txi_curated,
                                    colData = tmp_sample_merged,
                                    design = ~0 + SAMPLENAME)

vsd_all <- vst(ds_tpm_curated)

df_ctr_norm_curated <- as.data.frame(assay(vsd_all))

ctr_norm_curated <- df_ctr_norm_curated %>% 
  rownames_to_column(var = "SequenceID") %>% 
  left_join(taxfxn)
```

```{r}
save(ctr_norm_curated, ds_tpm_curated, file = "normed_center_df_curated_08252023.RData")
```

